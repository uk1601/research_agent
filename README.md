# ğŸ”¬ Research Paper Analyzer

> AI-powered research analysis platform built with [Subconscious AI](https://subconscious.dev) â€” Transform any research topic into comprehensive insights with reasoning traces.

[![Next.js](https://img.shields.io/badge/Next.js-15.5-black?logo=next.js)](https://nextjs.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109-009688?logo=fastapi)](https://fastapi.tiangolo.com/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.7-3178C6?logo=typescript)](https://www.typescriptlang.org/)
[![Python](https://img.shields.io/badge/Python-3.11+-3776AB?logo=python)](https://www.python.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“– Table of Contents

- [Overview](#-overview)
- [Features](#-features)
- [Architecture](#-architecture)
- [Quick Start](#-quick-start)
- [Configuration](#-configuration)
- [API Reference](#-api-reference)
- [Project Structure](#-project-structure)
- [Testing](#-testing)
- [Deployment](#-deployment)
- [Troubleshooting](#-troubleshooting)
- [Contributing](#-contributing)
- [License](#-license)

---

## ğŸ¯ Overview

Research Paper Analyzer is a full-stack application that leverages **Subconscious AI agents** to conduct comprehensive research on any topic. The AI agent uses multiple tools (web search, semantic search, ArXiv) to gather information, then synthesizes findings into structured analysis with full reasoning transparency.

### What makes it special?

- **Reasoning Transparency**: See exactly how the AI thinks with visual reasoning trees
- **Multi-Source Research**: Combines web search, Exa semantic search, and ArXiv academic papers
- **Real-Time Streaming**: Watch the research unfold in real-time with Server-Sent Events
- **Export Ready**: Download analysis as PDF or Markdown for sharing and archiving
- **Engine Selection**: Choose between different AI engines based on speed vs capability needs

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ¤– **AI-Powered Analysis** | Subconscious TIM engines with multi-tool orchestration |
| ğŸ” **Multi-Source Search** | Web search, Exa semantic search, ArXiv papers |
| ğŸŒŠ **Real-Time Streaming** | SSE streaming with instant event delivery |
| ğŸŒ³ **Reasoning Trees** | Interactive visualization of agent thought process |
| ğŸ“Š **Structured Output** | Papers, themes, gaps, and future directions |
| ğŸ“¥ **Export Options** | PDF and Markdown export with professional formatting |
| âš™ï¸ **Engine Selection** | TIM Small (fast), TIM GPT, TIM Large (capable) |
| ğŸ”§ **Tool Toggles** | Enable/disable individual research tools |
| ğŸŒ™ **Dark Theme** | Modern UI with Subconscious orange accents |
| ğŸ“± **Responsive** | Works on desktop and mobile devices |

---

## ğŸ— Architecture

### System Overview

```mermaid
flowchart TB
    subgraph Client["ğŸ–¥ï¸ Client Browser"]
        UI[Next.js Frontend<br/>Port 3000]
    end

    subgraph Backend["âš™ï¸ Backend Services"]
        API[FastAPI Backend<br/>Port 8000]
        ARXIV[ArXiv Service<br/>Port 8001]
    end

    subgraph External["â˜ï¸ External Services"]
        SUB[Subconscious API]
        ARXIV_API[ArXiv API]
        WEB[Web Search]
        EXA[Exa Search]
    end

    UI -->|SSE Stream| API
    API -->|SDK Calls| SUB
    API -->|HTTP| ARXIV
    ARXIV -->|Query| ARXIV_API
    SUB -->|Tools| WEB
    SUB -->|Tools| EXA

    style UI fill:#1a1a2e,stroke:#f97316,color:#fff
    style API fill:#1a1a2e,stroke:#f97316,color:#fff
    style ARXIV fill:#1a1a2e,stroke:#f97316,color:#fff
    style SUB fill:#f97316,stroke:#fff,color:#000
```

### Data Flow

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend
    participant B as Backend
    participant S as Subconscious
    participant T as Tools

    U->>F: Enter research topic
    F->>B: POST /analyze/stream
    B->>S: client.stream(instructions)
    
    loop Streaming Events
        S->>T: Execute tool calls
        T-->>S: Tool results
        S-->>B: Delta events
        B-->>F: SSE events
        F-->>U: Live updates
    end
    
    S-->>B: Done event
    B->>S: client.get(run_id)
    Note over B,S: Poll until status=succeeded
    S-->>B: Final result
    B-->>F: Answer + Reasoning
    F-->>U: Display results
```

### Reasoning Tree Structure

```mermaid
flowchart TD
    ROOT[ğŸ¯ Research Task]
    ROOT --> T1[ğŸ“‹ Task 1: Initial Search]
    ROOT --> T2[ğŸ“‹ Task 2: Deep Analysis]
    ROOT --> T3[ğŸ“‹ Task 3: Synthesis]
    
    T1 --> T1A[ğŸ”§ web_search]
    T1 --> T1B[ğŸ”§ arxiv_search]
    T1 --> T1C[ğŸ’­ Conclusion]
    
    T2 --> T2A[ğŸ”§ webpage_understanding]
    T2 --> T2B[ğŸ”§ exa_search]
    T2 --> T2C[ğŸ’­ Conclusion]
    
    T3 --> T3A[ğŸ’¡ Final Summary]

    style ROOT fill:#f97316,stroke:#fff,color:#000
    style T1C fill:#22c55e,stroke:#fff,color:#000
    style T2C fill:#22c55e,stroke:#fff,color:#000
    style T3A fill:#22c55e,stroke:#fff,color:#000
```

---

## ğŸš€ Quick Start

### Prerequisites

| Requirement | Version | Purpose |
|-------------|---------|---------|
| Node.js | 18+ | Frontend runtime |
| Python | 3.11+ | Backend runtime |
| Subconscious API Key | - | [Get one here](https://subconscious.dev) |

### Option 1: Docker Compose (Recommended)

```bash
# Clone and navigate
git clone <repository-url>
cd research-paper-analyzer-v2

# Configure environment
cp .env.example .env
# Edit .env and add SUBCONSCIOUS_API_KEY

# Launch all services
docker-compose up --build

# Open browser
open http://localhost:3000
```

### Option 2: Manual Setup

**Terminal 1 - ArXiv Service:**
```bash
cd arxiv-service
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
uvicorn main:app --host 0.0.0.0 --port 8001
```

**Terminal 2 - Backend:**
```bash
cd backend
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt

export SUBCONSCIOUS_API_KEY="your-api-key"
export ARXIV_SERVICE_URL="http://localhost:8001"

uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

**Terminal 3 - Frontend:**
```bash
cd frontend
npm install
npm run dev
```

**Open http://localhost:3000** ğŸ‰

---

## âš™ï¸ Configuration

### Environment Variables

#### Backend (`backend/.env`)

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `SUBCONSCIOUS_API_KEY` | âœ… | - | Your Subconscious API key |
| `SUBCONSCIOUS_ENGINE` | âŒ | `tim-large` | Default AI engine |
| `ARXIV_SERVICE_URL` | âŒ | `http://localhost:8001` | ArXiv service endpoint |
| `MAX_RETRIES` | âŒ | `5` | Max retry attempts |
| `RETRY_DELAY` | âŒ | `2` | Initial retry delay (seconds) |
| `LOG_LEVEL` | âŒ | `INFO` | Logging verbosity |

#### Frontend (`frontend/.env.local`)

| Variable | Required | Default | Description |
|----------|----------|---------|-------------|
| `NEXT_PUBLIC_API_URL` | âŒ | `http://localhost:8000` | Backend API URL |

### Available Engines

| Engine ID | Name | Description | Use Case |
|-----------|------|-------------|----------|
| `tim-small-preview` | TIM Small | Fast, lightweight | Quick queries |
| `tim-gpt` | TIM GPT | GPT-powered | Balanced performance |
| `tim-large` | TIM Large | Most capable | Deep research |

### Available Tools

| Tool ID | Name | Description |
|---------|------|-------------|
| `web_search` | Web Search | General web search |
| `webpage_understanding` | Webpage Understanding | Read and analyze web pages |
| `exa_search` | Exa Search | Semantic search engine |
| `arxiv_search` | ArXiv Search | Academic paper search (custom) |

---

## ğŸ“¡ API Reference

### Backend Endpoints

#### Health Check
```http
GET /health
```
Returns service health status.

#### List Engines
```http
GET /api/research/engines
```
Returns available AI engines.

#### List Tools
```http
GET /api/research/tools
```
Returns available platform tools.

#### Stream Analysis (Primary)
```http
POST /api/research/analyze/stream
Content-Type: application/json

{
  "topic": "transformer architectures in NLP",
  "engine": "tim-gpt",
  "tools": ["web_search", "exa_search"],
  "include_arxiv": true
}
```

**Response:** Server-Sent Events stream

| Event Type | Description |
|------------|-------------|
| `status` | Phase updates (init, connecting, researching, finalizing) |
| `activity` | Delta processing with content |
| `done` | Final answer and reasoning tree |
| `error` | Error message |

#### Get Run Status
```http
GET /api/research/status/{run_id}
```
Returns status of a specific run.

### ArXiv Service Endpoints

#### Search Papers
```http
POST /search
Content-Type: application/json

{
  "query": "attention mechanisms",
  "max_results": 10
}
```

---

## ğŸ“ Project Structure

```
research-paper-analyzer-v2/
â”‚
â”œâ”€â”€ ğŸ“‚ frontend/                    # Next.js 15 Application
â”‚   â”œâ”€â”€ ğŸ“‚ app/
â”‚   â”‚   â”œâ”€â”€ globals.css            # Global styles & dark theme
â”‚   â”‚   â”œâ”€â”€ layout.tsx             # Root layout with metadata
â”‚   â”‚   â””â”€â”€ page.tsx               # Main application page
â”‚   â”œâ”€â”€ ğŸ“‚ components/
â”‚   â”‚   â”œâ”€â”€ Header.tsx             # Application header
â”‚   â”‚   â”œâ”€â”€ SearchForm.tsx         # Topic input with options
â”‚   â”‚   â”œâ”€â”€ ReasoningTree.tsx      # Interactive tree view
â”‚   â”‚   â”œâ”€â”€ ActivityLog.tsx        # Real-time activity feed
â”‚   â”‚   â”œâ”€â”€ ExportButtons.tsx      # PDF/Markdown export
â”‚   â”‚   â””â”€â”€ RawJsonView.tsx        # Debug JSON viewer
â”‚   â”œâ”€â”€ ğŸ“‚ hooks/
â”‚   â”‚   â””â”€â”€ useStreamingSSE.ts     # SSE streaming hook
â”‚   â”œâ”€â”€ ğŸ“‚ lib/
â”‚   â”‚   â”œâ”€â”€ api.ts                 # API client functions
â”‚   â”‚   â”œâ”€â”€ store.ts               # Zustand state management
â”‚   â”‚   â”œâ”€â”€ types.ts               # TypeScript definitions
â”‚   â”‚   â””â”€â”€ export.ts              # PDF/Markdown generation
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ tailwind.config.js
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“‚ backend/                     # FastAPI Backend
â”‚   â”œâ”€â”€ ğŸ“‚ app/
â”‚   â”‚   â”œâ”€â”€ main.py                # Application entry point
â”‚   â”‚   â”œâ”€â”€ config.py              # Pydantic settings
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ health.py          # Health check endpoints
â”‚   â”‚   â”‚   â””â”€â”€ research.py        # Research API endpoints
â”‚   â”‚   â”œâ”€â”€ ğŸ“‚ services/
â”‚   â”‚   â”‚   â””â”€â”€ subconscious.py    # Subconscious SDK wrapper
â”‚   â”‚   â””â”€â”€ ğŸ“‚ models/
â”‚   â”‚       â”œâ”€â”€ schemas.py         # Request/response schemas
â”‚   â”‚       â””â”€â”€ types.py           # Type definitions
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“‚ arxiv-service/               # ArXiv Microservice
â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ğŸ“‚ docs/                        # Documentation
â”‚   â”œâ”€â”€ DEPLOYMENT.md              # Deployment guide
â”‚   â””â”€â”€ TESTING.md                 # Testing guide
â”‚
â”œâ”€â”€ docker-compose.yml              # Container orchestration
â”œâ”€â”€ .env.example                    # Environment template
â”œâ”€â”€ LICENSE                         # MIT License
â””â”€â”€ README.md                       # This file
```

---

## ğŸ§ª Testing

See [docs/TESTING.md](docs/TESTING.md) for comprehensive testing guide.

### Quick Test Commands

```bash
# Backend unit tests
cd backend
pytest tests/ -v

# Frontend type checking
cd frontend
npm run lint
npx tsc --noEmit

# Integration test (requires running services)
curl -X POST http://localhost:8000/api/research/analyze/stream \
  -H "Content-Type: application/json" \
  -d '{"topic": "machine learning basics", "include_arxiv": false}'
```

---

## ğŸš¢ Deployment

See [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) for comprehensive deployment guide.

### Quick Deploy to Vercel

**Frontend:**
```bash
cd frontend
vercel --prod
```

**Backend:** Deploy to Railway, Render, or any Docker-compatible platform.

---

## ğŸ› Troubleshooting

### Common Issues

| Issue | Solution |
|-------|----------|
| **"Engine warming up"** | Subconscious engines need warmup time. Retry logic handles this automatically. |
| **Empty analysis results** | Backend now polls until run status is `succeeded`. Check logs for polling progress. |
| **Streaming delays** | Updated to use `sse-starlette` + `@microsoft/fetch-event-source` for instant delivery. |
| **ArXiv not working** | Ensure ArXiv service is running and `ARXIV_SERVICE_URL` is correct. |
| **CORS errors** | Add your frontend URL to `CORS_ORIGINS` in backend config. |

### Debug Mode

Enable verbose logging:
```bash
# Backend
export LOG_LEVEL=DEBUG
uvicorn app.main:app --reload

# Frontend - check browser console for [SSE] logs
```

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit changes (`git commit -m 'Add amazing feature'`)
4. Push to branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Subconscious](https://subconscious.dev) - AI Agent Platform
- [ArXiv](https://arxiv.org) - Open Access Academic Papers
- [Vercel](https://vercel.com) - Frontend Deployment
- [FastAPI](https://fastapi.tiangolo.com) - Backend Framework

---

<div align="center">

**Built with â¤ï¸ using [Subconscious AI](https://subconscious.dev)**

[Report Bug](../../issues) Â· [Request Feature](../../issues) Â· [Documentation](https://docs.subconscious.dev)

</div>
